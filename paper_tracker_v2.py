#!/usr/bin/env python3
"""
 Jarvis AI Paper Tracker - Intelligent Version
 Orchestrates arXiv fetching, Claude Code review, and Telegram delivery
"""

import json
import subprocess
import re
from datetime import datetime

CONFIG = {
    'arxiv_categories': ['cs.AI', 'cs.LG', 'cs.MA'],
    'keywords': ['agent', 'multi-agent', 'collaboration', 'coordination', 
                 'task planning', 'llm', 'reasoning', 'autonomous', 'swarm', 
                 'collective', 'reinforcement', 'hierarchical', 'distributed',
                 'emergent', 'foundation model'],
    'max_papers': 20,
}

REVIEW_PROMPT = """You are an expert AI researcher. Review these arXiv papers for a multi-agent systems researcher.

Papers:
{papers}

For each paper:
1. Relevance Score (1-5): Relevance to multi-agent systems, LLM agents, collaborative AI?
2. Key Insight: One sentence explaining the main contribution.
3. Should Read? (yes/no/maybe)
4. Tags: Choose from [multi-agent, planning, reasoning, LLM, swarm, coordination, theory, application, survey]

Return pure JSON:
{{
  "reviews": [{{"id": "xxx", "score": 5, "key_insight": "...", "should_read": "yes", "tags": ["multi-agent"]}}],
  "summary": "Brief 2-3 sentence overview of the research landscape",
  "top_pick": "ID of the most important paper"
}}
"""

def fetch_arxiv_papers():
    """Fetch papers from arXiv API using curl"""
    papers = []
    
    for category in CONFIG['arxiv_categories']:
        url = f'https://export.arxiv.org/api/query?search_query=cat:{category}&start=0&max_results=30&sortBy=submittedDate&sortOrder=descending'
        
        result = subprocess.run(['curl', '-sL', url], capture_output=True, text=True, timeout=30)
        data = result.stdout
        entries = re.findall(r'<entry>(.*?)</entry>', data, re.DOTALL)
        
        for entry in entries:
            id_match = re.search(r'<id>(.*?)</id>', entry)
            if id_match:
                raw_id = id_match.group(1)
                paper_id = raw_id.split('/abs/')[-1].split('v')[0]
            else:
                continue
            
            title_match = re.search(r'<title>(.*?)</title>', entry, re.DOTALL)
            title = title_match.group(1).replace('\n', ' ').strip() if title_match else "No title"
            
            summary_match = re.search(r'<summary>(.*?)</summary>', entry, re.DOTALL)
            summary = summary_match.group(1).replace('\n', ' ').strip() if summary_match else ""
            
            authors = re.findall(r'<name>(.*?)</name>', entry)
            published_match = re.search(r'<published>(\d{4}-\d{2}-\d{2})</published>', entry)
            published = published_match.group(1) if published_match else "2026-01-01"
            
            text = (title + ' ' + summary).lower()
            score = sum(1 for kw in CONFIG['keywords'] if kw in text)
            
            if score > 0:
                papers.append({
                    'id': paper_id,
                    'title': title,
                    'summary': summary[:400],
                    'authors': authors[:3],
                    'published': published,
                    'url': f'https://arxiv.org/abs/{paper_id}',
                    'raw_score': score,
                    'category': category
                })
    
    papers.sort(key=lambda x: (-x['raw_score'], x['published']))
    seen = set()
    unique_papers = []
    for p in papers:
        if p['id'] not in seen:
            seen.add(p['id'])
            unique_papers.append(p)
    
    return unique_papers[:CONFIG['max_papers']]

def review_with_claude_code(papers):
    """Send papers to Claude Code for intelligent review"""
    if not papers:
        return None
    
    papers_json = json.dumps([{
        'id': p['id'],
        'title': p['title'],
        'summary': p['summary'],
        'authors': p['authors'],
        'published': p['published'],
        'url': p['url'],
        'category': p['category']
    } for p in papers], indent=2, ensure_ascii=False)
    
    prompt = REVIEW_PROMPT.format(papers=papers_json)
    
    try:
        result = subprocess.run(
            ['claude', '-p', prompt],
            capture_output=True,
            text=True,
            timeout=120
        )
        
        if result.returncode == 0:
            json_match = re.search(r'\{[\s\S]*\}', result.stdout)
            if json_match:
                return json.loads(json_match.group())
    except Exception as e:
        print(f"Claude Code review failed: {e}")
    
    return None

def format_briefing(papers, review_result):
    """Compile papers and review into a nice briefing"""
    if not papers:
        return None
    
    date = datetime.now().strftime('%Y-%m-%d')
    briefing = f"ğŸ“š **Jarvis è®ºæ–‡ç®€æŠ¥** - {date}\n\n"
    briefing += f"ğŸ” ä» arXiv æŠ“å– {len(papers)} ç¯‡ç›¸å…³è®ºæ–‡\n"
    
    if review_result:
        briefing += f"ğŸ§  Claude Code æ™ºèƒ½å®¡é˜…å®Œæˆ\n\n"
        briefing += f"---\n\n{review_result.get('summary', '')}\n\n"
        briefing += f"---\n\n"
        
        reviews = {r['id']: r for r in review_result.get('reviews', [])}
        
        for paper in papers:
            review = reviews.get(paper['id'], {})
            should_read = review.get('should_read', 'maybe')
            
            if should_read == 'yes':
                icon = "â­â­â­"
            elif should_read == 'maybe':
                icon = "â­"
            else:
                icon = "â—‹"
            
            tags = ', '.join(review.get('tags', []))
            key_insight = review.get('key_insight', '')[:100]
            
            briefing += f"{icon} **{paper['title'][:70]}...**\n"
            briefing += f"ğŸ“… {paper['published']} | {paper['category']}\n"
            if tags:
                briefing += f"Tags: {tags}\n"
            if key_insight:
                briefing += f"ğŸ’¡ {key_insight}\n"
            briefing += f"ğŸ”— [arXiv]({paper['url']})\n\n"
    else:
        for paper in papers[:5]:
            stars = "â­" * min(paper['raw_score'], 5)
            briefing += f"{stars} **{paper['title'][:60]}...**\n"
            briefing += f"ğŸ“… {paper['published']} | [arXiv]({paper['url']})\n\n"
    
    briefing += f"---\nğŸ¤– Jarvis AI è®ºæ–‡åŠ©æ‰‹ | å…± {len(papers)} ç¯‡"
    
    return briefing

def send_to_telegram(message):
    """Send briefing to Harry via Clawdbot"""
    if not message:
        return False
    
    try:
        with open('/home/ubuntu/.clawdbot/config.json', 'r') as f:
            config = json.load(f)
        gateway_url = config.get('gatewayUrl', 'http://localhost:5000')
    except:
        gateway_url = 'http://localhost:5000'
    
    data = {
        "action": "send",
        "channel": "telegram",
        "target": "8077045709",
        "message": message
    }
    
    try:
        import urllib.request
        req = urllib.request.Request(
            f"{gateway_url}/api/message",
            data=json.dumps(data).encode('utf-8'),
            headers={'Content-Type': 'application/json'}
        )
        with urllib.request.urlopen(req, timeout=10) as response:
            return True
    except Exception as e:
        print(f"Telegram send failed: {e}")
        return False

def main():
    print(f"\nğŸ¤– Jarvis è®ºæ–‡åŠ©æ‰‹ - {datetime.now().strftime('%H:%M')}")
    print("=" * 50)
    
    print("ğŸ“¥ Step 1: ä» arXiv æŠ“å–è®ºæ–‡...")
    papers = fetch_arxiv_papers()
    print(f"   æ‰¾åˆ° {len(papers)} ç¯‡ç›¸å…³è®ºæ–‡")
    
    if not papers:
        print("   æ²¡æœ‰æ‰¾åˆ°æ–°è®ºæ–‡")
        return
    
    print("ğŸ§  Step 2: å‘é€è‡³ Claude Code æ™ºèƒ½å®¡é˜…...")
    review_result = review_with_claude_code(papers)
    if review_result:
        print("   âœ… Claude Code å®¡é˜…å®Œæˆ")
    else:
        print("   âš ï¸ Claude Code ä¸å¯ç”¨ï¼Œä½¿ç”¨åŸºç¡€è¯„åˆ†")
    
    print("ğŸ“ Step 3: æ’°å†™ç®€æŠ¥...")
    briefing = format_briefing(papers, review_result)
    
    print("ğŸ“¤ Step 4: å‘é€è‡³ Telegram...")
    if send_to_telegram(briefing):
        print("   âœ… å·²å‘é€ï¼")
    else:
        print("   âš ï¸ å‘é€å¤±è´¥ï¼Œä»…æ‰“å°")
        print("\n" + briefing)

if __name__ == "__main__":
    main()
